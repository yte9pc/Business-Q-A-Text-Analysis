{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETA Project\n",
    "By Yihnew Eshetu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TOKEN, LIB, and VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from scipy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yte9pc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yte9pc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHCO Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['file_id', 'company', 'title', 'speaker', 'sent_num', 'token_num']\n",
    "SENTS = OHCO[:5]\n",
    "SPEAKER = OHCO[:4]\n",
    "TITLE = OHCO[:3]\n",
    "COMPANY = OHCO[:2]\n",
    "FILE = OHCO[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/qumulo/qhome/yte9pc/ETA Project/Transcript/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks = os.getcwd()\n",
    "transcript_path = notebooks + '/Transcript/'\n",
    "transcript_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTxt(file_list):\n",
    "    lib = []\n",
    "    doc = []\n",
    "    count = 0\n",
    "    for file_name in file_list:\n",
    "        file = open(file_name, 'r', encoding='ISO-8859-1').read()\n",
    "        if re.search('\\sQUESTIONS\\sAND\\sANSWERS\\s-', file, re.I) is not None:\n",
    "            txt = re.sub('COMPANY\\sDISCLAIMERS\\sImportant(.+)', '', file, flags=re.I)\n",
    "            txt = re.sub('\\sQUESTIONS\\sAND\\sANSWERS\\s-', '  QUESTIONS AND ANSWERS - ', txt, flags=re.I)\n",
    "        elif re.search('\\s\\sQUESTIONS\\sAND\\sANSWERS\\s', file, re.I) is not None:\n",
    "            txt = re.sub('COMPANY\\sDISCLAIMERS\\sImportant(.+)', '', file, flags=re.I)\n",
    "            txt = re.sub('\\s\\sQUESTIONS\\sAND\\sANSWERS\\s', '  QUESTIONS AND ANSWERS - ', txt, flags=re.I)\n",
    "        else:\n",
    "            count += 1\n",
    "            continue\n",
    "                    \n",
    "        txt = re.split('\\s\\sQUESTIONS\\sAND\\sANSWERS\\s-\\s', txt, re.I)\n",
    "        \n",
    "        title = txt[0].split('--')[0].split('\\t\"')[1].split('  ')\n",
    "        report_title = title[0]\n",
    "        date = re.search(r'[a-z]+\\s(\\d{2}|\\d{1}),\\s\\d{4}', title[1], re.I).group()\n",
    "        \n",
    "        txt = re.sub('^------------------------------------------------------------------------------- ', '', txt[1])\n",
    "        txt = re.sub('\\s\\s', ' -------------------------------------------------------------------------------- ', txt)\n",
    "        txt = re.sub('\\[([0-9]+)\\]', '[1] -------------------------------------------------------------------------------- ', txt)\n",
    "        txt = re.split(r' -------------------------------------------------------------------------------- ', txt)\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(txt, columns=['line_str'])\n",
    "        \n",
    "        company = file_name.split('/')[0]\n",
    "        file_id = file_name.split('/')[1].split('_')[0]\n",
    "        df['file_id'] = file_id\n",
    "        df['company'] = company\n",
    "        df['title'] = report_title\n",
    "        \n",
    "        speakers_lines = df.line_str.map(lambda x: str(x)[-4:].strip()).str.lower().str.match(pat = '[\\[]+[0-9]+') \n",
    "        speakers = [i for i in df.loc[speakers_lines].line_str.map(lambda x: str(x).split(',')[0].split(' [')[0]).values]\n",
    "        df.loc[speakers_lines, 'speaker'] = speakers\n",
    "        df.speaker = df.speaker.ffill()\n",
    "        df = df.loc[~df.speaker.isna()] \n",
    "        df = df.loc[~speakers_lines]\n",
    "        \n",
    "        # Speaker\n",
    "        df['line_str'] = df['line_str'].str.strip()\n",
    "        dfc = df.groupby(OHCO[:4]).line_str.apply(lambda x: '\\n'.join(x)).to_frame() # Make big string\n",
    "    \n",
    "        # Sentence\n",
    "        dfc['line_str'] = dfc['line_str'].str.strip()\n",
    "        dfc = dfc[~dfc['line_str'].str.match(r'^\\s*$')]\n",
    "        dfs = dfc['line_str'].str.split(r'[.?!;:\"]+', expand=True).stack().to_frame().rename(columns={0:'sent_str'})\n",
    "        dfs.index.names = OHCO[:5]\n",
    "        \n",
    "        # Token\n",
    "        dfs['sent_str'] = dfs['sent_str'].str.strip()\n",
    "        dft = dfs['sent_str'].str.split(r\"[\\s',-]+\", expand=True).stack().to_frame().rename(columns={0:'token_str'})\n",
    "        dft.index.names = OHCO[:6]\n",
    "        \n",
    "        lib.append((file_id, company, date, report_title, file_name))\n",
    "        doc.append(dfc)\n",
    "        \n",
    "\n",
    "    library = pd.DataFrame(lib, columns=['file_id', 'company', 'date', 'title', 'file_name'])\n",
    "    docs = pd.concat(doc)\n",
    "    return docs, library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(transcript_path)\n",
    "companies = ['Cisco', 'IBM', 'Intel', 'Verizon']\n",
    "list_files = [file for company in companies for file in sorted(glob(company + '/*.txt'))]\n",
    "doc, lib = readTxt(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>line_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">575f8b498cfe5b23768b45e8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Cisco</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Q3 2016 Cisco Systems Inc Earnings Call</th>\n",
       "      <th>Brent Bracelin</th>\n",
       "      <td>Thank you for taking the question. Chuck, I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brian White</th>\n",
       "      <td>I'm wondering if you could walk us through wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chuck Robbins</th>\n",
       "      <td>Ittai, this is Chuck. Thanks for the questions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ittai Kidron</th>\n",
       "      <td>Thanks, and congrats on great execution. First...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James Faucette</th>\n",
       "      <td>Great, thank you very much. I just had a clari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                  line_str\n",
       "file_id                  company title                                   speaker                                                          \n",
       "575f8b498cfe5b23768b45e8 Cisco   Q3 2016 Cisco Systems Inc Earnings Call Brent Bracelin  Thank you for taking the question. Chuck, I wa...\n",
       "                                                                         Brian White     I'm wondering if you could walk us through wha...\n",
       "                                                                         Chuck Robbins   Ittai, this is Chuck. Thanks for the questions...\n",
       "                                                                         Ittai Kidron    Thanks, and congrats on great execution. First...\n",
       "                                                                         James Faucette  Great, thank you very much. I just had a clari..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(notebooks)\n",
    "dataset_path = 'dataset/processed-files/final'\n",
    "dataset_folder = Path('dataset/processed-files/final')\n",
    "dataset_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(dataset_folder/'DOC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib['year'] = lib.date.map(lambda x: str(x).strip()).str.extract(pat = '(\\d{4})')\n",
    "lib = lib[['file_id', 'file_name', 'company', 'title', 'date', 'year']].set_index('file_id')\n",
    "lib.to_csv(dataset_folder/'LIB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function for Tokenizing doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.line_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = tokenize(doc, ws=True)\n",
    "# Remove white space\n",
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VOCAB from TOKEN table\n",
    "VOCAB = TOKEN.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'\n",
    "# Check if a term string is a number\n",
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem VOCAB term string\n",
    "stemmer = PorterStemmer()\n",
    "VOCAB['p_stem'] = VOCAB.term_str.apply(stemmer.stem)\n",
    "# Add term id to TOKEN table\n",
    "TOKEN['term_id'] = TOKEN.term_str.map(VOCAB.reset_index().set_index('term_str').term_id)\n",
    "# Add part of speech max to VOCAB table\n",
    "VOCAB['pos_max'] = TOKEN.groupby(['term_id', 'pos']).count().iloc[:,0].unstack().idxmax(1)\n",
    "# Add stop word\n",
    "stops = set(stopwords.words(\"english\"))    \n",
    "VOCAB['is_stopword'] = VOCAB['term_str'].apply(lambda x: x in stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty term string rows in TOKEN and VOCAB table\n",
    "TOKEN = TOKEN[~TOKEN.term_str.isna()]\n",
    "VOCAB = VOCAB[~VOCAB.term_str.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">575f8b498cfe5b23768b45e8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Cisco</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Q3 2016 Cisco Systems Inc Earnings Call</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Brent Bracelin</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Thank, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Thank</td>\n",
       "      <td>thank</td>\n",
       "      <td>26308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(you, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>29413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(for, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>11078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(taking, VBG)</td>\n",
       "      <td>VBG</td>\n",
       "      <td>taking</td>\n",
       "      <td>taking</td>\n",
       "      <td>25912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>26334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                pos_tuple  \\\n",
       "file_id                  company title                                   speaker        sent_num token_num                  \n",
       "575f8b498cfe5b23768b45e8 Cisco   Q3 2016 Cisco Systems Inc Earnings Call Brent Bracelin 0        0           (Thank, NNP)   \n",
       "                                                                                                 1             (you, PRP)   \n",
       "                                                                                                 2              (for, IN)   \n",
       "                                                                                                 3          (taking, VBG)   \n",
       "                                                                                                 4              (the, DT)   \n",
       "\n",
       "                                                                                                            pos  \\\n",
       "file_id                  company title                                   speaker        sent_num token_num        \n",
       "575f8b498cfe5b23768b45e8 Cisco   Q3 2016 Cisco Systems Inc Earnings Call Brent Bracelin 0        0          NNP   \n",
       "                                                                                                 1          PRP   \n",
       "                                                                                                 2           IN   \n",
       "                                                                                                 3          VBG   \n",
       "                                                                                                 4           DT   \n",
       "\n",
       "                                                                                                           token_str  \\\n",
       "file_id                  company title                                   speaker        sent_num token_num             \n",
       "575f8b498cfe5b23768b45e8 Cisco   Q3 2016 Cisco Systems Inc Earnings Call Brent Bracelin 0        0             Thank   \n",
       "                                                                                                 1               you   \n",
       "                                                                                                 2               for   \n",
       "                                                                                                 3            taking   \n",
       "                                                                                                 4               the   \n",
       "\n",
       "                                                                                                           term_str  \\\n",
       "file_id                  company title                                   speaker        sent_num token_num            \n",
       "575f8b498cfe5b23768b45e8 Cisco   Q3 2016 Cisco Systems Inc Earnings Call Brent Bracelin 0        0            thank   \n",
       "                                                                                                 1              you   \n",
       "                                                                                                 2              for   \n",
       "                                                                                                 3           taking   \n",
       "                                                                                                 4              the   \n",
       "\n",
       "                                                                                                            term_id  \n",
       "file_id                  company title                                   speaker        sent_num token_num           \n",
       "575f8b498cfe5b23768b45e8 Cisco   Q3 2016 Cisco Systems Inc Earnings Call Brent Bracelin 0        0            26308  \n",
       "                                                                                                 1            29413  \n",
       "                                                                                                 2            11078  \n",
       "                                                                                                 3            25912  \n",
       "                                                                                                 4            26334  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>p_stem</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>is_stopword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>28456</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>:</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0001</td>\n",
       "      <td>CD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0004</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num p_stem pos_max  is_stopword\n",
       "term_id                                                 \n",
       "0                 28456    0              :        False\n",
       "1              0     46    1      0      CD        False\n",
       "2             00      9    1     00      VB        False\n",
       "3           0001      1    1   0001      CD        False\n",
       "4           0004      2    1   0004      NN        False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN.to_csv(dataset_folder/'TOKEN.csv')\n",
    "VOCAB.to_csv(dataset_folder/'VOCAB.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
